{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BN254 with Thresholding\n",
    "\n",
    "yeah ok this isn't proper code, but I need to get in my head an idea of what an impl from \"scratch\" would look like \n",
    "\n",
    "### Contents\n",
    "[Step 0: Roadmap](#Step-0:-Roadmap)\n",
    "\n",
    "[Step 1: Generate field scalars](#Step-1:-generate-field-scalars)\n",
    "\n",
    "[Step 2: Generate partial private shares](#Step-2:-generate-partial-private-shares)\n",
    "\n",
    "[Step 3: Create public polynomial](#Step-3:-create-public-polynomial)\n",
    "\n",
    "[Step 4: partial signaturing](#Step-4:-partial-signaturing)\n",
    "\n",
    "[Step 5: partial verification](#Step-5:-partial-verification)\n",
    "\n",
    "[Step 6: aggregation](#Step-6:-aggregation)\n",
    "\n",
    "[Step 7: final verify](#Step-7:-final-verify)\n",
    "\n",
    "### tl;dr\n",
    "\n",
    "\n",
    "There are a lot of good partial implementations of everything in this document. my recommendation is to start with [seda's barebones of bn254](https://github.com/sedaprotocol/bn254) and the [pairing library here](https://github.com/paritytech/bn) to create our skeleton. These two libraries have minimal external dependencies, and are lightwight renditions of the functionality. We then take the thresholding logic of [threshold_bls](https://github.com/ARPA-Network/BLS-TSS-Network/tree/75da9ae432516002b12e37b16b4a4b3568c79529/crates/threshold-bls) for the  partial signature generation and aggregation, etc. (all of its curve logic is imported from external crates so I don't recommend starting off with this).\n",
    "\n",
    "The biggest issue in these existing repos is the security concerns regarding the `hash_to_field` and `field_to_curve` functions, which are only implemented with naïve algorithms in these repos. Fortunately, there is a clear guide to developing secure elliptic curve suites created by cloudflare called [RFC 9380](https://datatracker.ietf.org/doc/html/rfc9380) which specifies very clearly, with example algorithms, references, and precise language, how to remedy these issues, and what algorithms to use for which curves, security levels, etc.\n",
    "\n",
    "There are implementations by [arkworks](https://github.com/arkworks-rs/algebra/tree/master/curves/bn254) and [zkcrypto/bls12_381](https://github.com/zkcrypto/bls12_381/tree/main). Arkworks unfortunately is extermely bloated and very massive for something that only provides the elliptic curve logic, and zkcrpto/bls12_381 is the wrong curve. However,  arkworks is a good reference for our friendly bn254, and zkcrypto/bls12_381 conforms to security standards set out in RFC9380, so they should be good references while we build our product.\n",
    "\n",
    "#### performance points\n",
    "\n",
    "- Montgomery arithmetic: simplifies operations, and for curves in the right functional form helps performance re addition and doubling ops\n",
    "- Scalar reps: decompose 256bit into 4x64bit limbs for individual manipulation and storage\n",
    "    \n",
    "### Step 0: Roadmap \n",
    "\n",
    "For the BN254 curve, there are two groups we will deal with often.\n",
    "\n",
    "##### $\\mathbb{G}_1\\subset\\mathrm{E}(\\mathbb{F}_r)$ with $\\rm E$ the curve\n",
    "\n",
    "- This is the group of points on the base curve in short Weierstrass form $y^2=x^3+3$ defined over the field $\\mathbb{F}_r$\n",
    "\n",
    "##### $\\mathbb{G}_2\\subset\\mathrm{E}^\\prime(\\mathbb{F}_{r^2})$ with $\\rm E^\\prime$ the sextic twist of the curve\n",
    "\n",
    "- This is the group of points on the twisted curve defined over the quadratic extension field $\\mathbb{F}_{r^2}$, defined by $y^2=x^3+\\frac{3}{i+9}$\n",
    "\n",
    "---\n",
    "\n",
    "1. Generate scalars $\\{a_0,\\ldots,a_{t-1}\\}$ in the field $\\mathbb{F}_r$\n",
    "    a. These define private key polynomial coefficients\n",
    "2. Generate partial key shares by evaluating the polynomial for $n$ shares, making sure to never evalaute at 0\n",
    "    a. This creates partial priate keys $s_i\\in\\mathbb{F}_r$\n",
    "3. Commit the private polynomial to $\\mathbb{G}_2$ to create the public key polynomial\n",
    "    a. Define $A:\\mathbb{F}_r\\to\\mathbb{G}_2:x\\to xg_2$, and apply to polynomial, namely $a_i\\to A(a_i)=a_ig_2$\n",
    "    b. The group public key is the evalution of the public key polynomial at $0\\in\\mathbb{F}_r$, namely $a_0g_2$\n",
    "4. Each node $i$ will now create a partial signature\n",
    "    a. First, hash message $m$ into $\\mathbb{F}_r$ \n",
    "    b. Second, take the hash and map it to the curve, generating $H(m)\\in\\mathbb{G}_1$\n",
    "    c. Thirdly, create the partial signature by multiplying by the partial key share $s_i\\in\\mathbb{F}_r$ by the hash, $\\sigma_i=s_iH(m)\\in\\mathbb{G}_1$\n",
    "    \n",
    "5. Verify the partial signatures against the public polynomial\n",
    "    a. Now having the hash on the curve $H(m)$, and the partial signature $\\sigma_i$, we first evaluate the public polynomial $P(x) = a_0g_2 + a_1g_2x+\\cdots+a_{t-1}g_2x^{t-1}$ at each index $i$\n",
    "    b. We then use the pairing function to verify $e(\\sigma_i, g_2)=e(H(m), P(i))$ \n",
    "    \n",
    "6. Aggregate the participants and their partial signatures to recover the public polynomial constant term, aka pub key $a_0g_2$, via generation of total signature $\\sigma$\n",
    "\n",
    "7. Use same methodology as step 5 to verify the final signature $e(\\sigma, g_2)=\\prod_i e(H(m),P(i) )$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: generate field scalars\n",
    "\n",
    "#### Listing 1: Generate $s\\in\\mathbb{F}_r$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [],
   "source": [
    "use rand::Rng;\n",
    "\n",
    "#[derive(Debug, Clone, Copy)]\n",
    "pub struct Scalar([u64; 4]);\n",
    "\n",
    "impl Scalar {\n",
    "    // The modulus q of BN254 curve\n",
    "    const MODULUS: [u64; 4] = [\n",
    "        0x43e1f593f0000001,\n",
    "        0x2833e84879b97091,\n",
    "        0xb85045b68181585d,\n",
    "        0x30644e72e131a029,\n",
    "    ];\n",
    "\n",
    "    // R^2 mod q (used for conversion to Montgomery form)\n",
    "    const R2: [u64; 4] = [\n",
    "        0x1bb8e645ae216da7,\n",
    "        0x53fe3ab1e35c59e3,\n",
    "        0x8c49833d53bb8085,\n",
    "        0x0216d0b17f4e44a5,\n",
    "    ];\n",
    "\n",
    "    // Generate a random Scalar\n",
    "    pub fn random() -> Self {\n",
    "        let mut rng = rand::thread_rng();\n",
    "        let mut limbs = [0u64; 4];\n",
    "        \n",
    "        loop {\n",
    "            for i in 0..4 {\n",
    "                limbs[i] = rng.gen();\n",
    "            }\n",
    "            \n",
    "            // Ensure the generated number is less than the modulus\n",
    "            if !Self::is_above_modulus(&limbs) {\n",
    "                break;\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // Convert to Montgomery form\n",
    "        Self::to_montgomery_form(&limbs)\n",
    "    }\n",
    "\n",
    "    // Check if the generated number is above or equal to the modulus\n",
    "    fn is_above_modulus(limbs: &[u64; 4]) -> bool {\n",
    "        for i in (0..4).rev() {\n",
    "            if limbs[i] > Self::MODULUS[i] {\n",
    "                return true;\n",
    "            }\n",
    "            if limbs[i] < Self::MODULUS[i] {\n",
    "                return false;\n",
    "            }\n",
    "        }\n",
    "        true\n",
    "    }\n",
    "\n",
    "    // Convert to Montgomery form\n",
    "    fn to_montgomery_form(limbs: &[u64; 4]) -> Self {\n",
    "        let mut result = [0u64; 4];\n",
    "        Self::montgomery_multiply(limbs, &Self::R2, &mut result);\n",
    "        Scalar(result)\n",
    "    }\n",
    "\n",
    "    // Montgomery multiplication\n",
    "    fn montgomery_multiply(a: &[u64; 4], b: &[u64; 4], result: &mut [u64; 4]) {\n",
    "        let mut t = [0u64; 8];\n",
    "\n",
    "        // Multiply\n",
    "        for i in 0..4 {\n",
    "            let mut carry = 0u64;\n",
    "            for j in 0..4 {\n",
    "                let mut product = (a[i] as u128) * (b[j] as u128) + (t[i + j] as u128) + (carry as u128);\n",
    "                t[i + j] = product as u64;\n",
    "                carry = (product >> 64) as u64;\n",
    "            }\n",
    "            t[i + 4] = carry;\n",
    "        }\n",
    "\n",
    "        // Reduce\n",
    "        let mut carry = 0u64;\n",
    "        for i in 0..4 {\n",
    "            //rando num below is INV=(-q^{-1}mod 2^64)mod 2^64\n",
    "            //its giving fast inv square root vibes\n",
    "            let k = t[i].wrapping_mul(0xac96341c4ffffffb);\n",
    "            let mut sum = (t[i] as u128) + (k as u128) * (Self::MODULUS[0] as u128) + (carry as u128);\n",
    "            carry = (sum >> 64) as u64;\n",
    "            for j in 1..4 {\n",
    "                sum = (t[i + j] as u128) + (k as u128) * (Self::MODULUS[j] as u128) + (carry as u128);\n",
    "                t[i + j - 1] = sum as u64;\n",
    "                carry = (sum >> 64) as u64;\n",
    "            }\n",
    "            t[i + 3] = carry;\n",
    "            carry = 0;\n",
    "        }\n",
    "\n",
    "        result.copy_from_slice(&t[4..8]);\n",
    "\n",
    "        // Final reduction\n",
    "        if Self::is_above_modulus(result) {\n",
    "            let mut borrow = 0i64;\n",
    "            for i in 0..4 {\n",
    "                let diff = (result[i] as i128) - (Self::MODULUS[i] as i128) - (borrow as i128);\n",
    "                result[i] = diff as u64;\n",
    "                borrow = if diff < 0 { -1 } else { 0 };\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many implementations exist. Best ones so far I've found that could add rto the barebones scalar above have montgomery arithmetic added. Consider  [this](https://github.com/arkworks-rs/algebra/blob/5a781ae69c373e46c8d738d147a764a8ee510865/ff/src/fields/models/fp/montgomery_backend.rs#L392) and [that](https://github.com/zkcrypto/bls12_381/blob/4df45188913e9d66ef36ae12825865347eed4e1b/src/scalar.rs#L554)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: generate partial private shares\n",
    "\n",
    "#### Listing 2: evaluate private polynomial at each index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [],
   "source": [
    "#[derive(Debug, Clone, Serialze, Deserialize)]\n",
    "pub struct Eval<A> {\n",
    "    pub idx: u32;\n",
    "    pub val: A\n",
    "}\n",
    "let (n, t) = (10, 6);\n",
    "let coeffs: Vec<Scalar> = (0..t).map(|_|Scalar::random()).collect();\n",
    "\n",
    "//eval polynomial f(i), but never for i=0 since that exposes the secret\n",
    "let private_shares = (0..n).map(|i| {\n",
    "    coeffs.iter().rev().fold(Scalar::zero(), |mut sum, coeff| {\n",
    "        sum.mul(i+1);\n",
    "        sum.add(coeff);\n",
    "        Eval<Scalar> {\n",
    "            idx: i+1,\n",
    "            value: sum\n",
    "        }\n",
    "    }\n",
    "}).collect::<Vec<_>>();\n",
    "//put in eval struct or something for clarity / serialization later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Now we have evaluated the polynomial $f(x) = a_0 +a_1x+\\cdots+a_{t-1}x^{t-1}$. Now we get to the fun stuff \n",
    "\n",
    "### Step 3: create public polynomial\n",
    "\n",
    "First, we need to commit the scalar polynomial generated above to the group to get polynomial on the group, aka multiply each coeff by the generator. We call it committing because of the close connection to [KZG polynomials](https://www.iacr.org/archive/asiacrypt2010/6477178/6477178.pdf) in SNARKS (a good blog on it is [here](https://dankradfeist.de/ethereum/2020/06/16/kate-polynomial-commitments.html)). \n",
    "\n",
    "all of arkworks-rs, zkcrypto/bls12_381, an threshold_bls implement a struct specifically mapping a Scalar of the field to point on $\\mathbb{G}_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [],
   "source": [
    "let public_polynomial_g2_coeffs = coeffs.iter().map(|c|{\n",
    "    let mut commit = <cofactor of G2>;\n",
    "    commit.mul(c);\n",
    "    commit\n",
    "}).collect::<Vec<<stuct of points on the field>>>();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then BAM, we get the public key for \"free\" since its just the constant term of the polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [],
   "source": [
    "let pub_key:<stuct of points on the field> = public_polynomial_g2_coeffs[0];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We place the public key as an element of G2. Why?\n",
    "- prevents rogue key attacks, since more complex structure makes it harder to generate fake pub keys\n",
    "- subgroup structure is more complex, so harder to cofactor clear\n",
    "- allows for optimizations in the pairing equation\n",
    "\n",
    "Also, note that in order to get an element of G2 we multiply by the cofactor, see [membership checks](#Membership-checks). The problem is really that this cofactor is huge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#E'(F_{p^2}) = 479095176016622842441988045216678740799252316531100822436447802254070093686356349204969212544220033486413271283566945264650845755880805213916963058350733\n",
    "c_2 = 21888242871839275222246405745257275088844257914179612981679871602714643921549"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so there are [faster ways to generate an element in G2](https://datatracker.ietf.org/doc/html/rfc9380#name-clearing-the-cofactor), for example [this](https://eprint.iacr.org/2017/419.pdf). \n",
    "### Step 4: partial signaturing\n",
    "ok, great. c'est parti à la lune . we now need to partial sign messages. this is distributed obvs in our case, but for here it'd be nice to have something like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [],
   "source": [
    "let partials_sigs_g1 = private_shares.iter().map(|s| bn254::partial_sign(s, &msg));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but what does this actually entail? this is the good stuff. \n",
    "\n",
    "##### Choose an upper bound on the target security level $k$, a reasonable choice of which is $\\lceil\\log_2(r)/2\\rceil$\n",
    "\n",
    "##### Define a hash_to_field function to take byte strings to field\n",
    "\n",
    "From RFC 9380, \n",
    ">To control bias, hash_to_field instead uses random integers whose length is at least $\\lceil \\log_2(p)\\rceil + k$ bits, where k is the target security level for the suite in bits. Reducing such integers mod p gives bias at most 2^-k for any p; this bias is appropriate when targeting k-bit security. For each such integer, hash_to_field uses expand_message to obtain L uniform bytes, where $L = \\lceil(\\lceil\\log_2(p)\\rceil + k) / 8\\rceil$. These uniform bytes are then interpreted as an integer via OS2IP. For example, for a 255-bit prime p, and k = 128-bit security, L = ceil((255 + 128) / 8) = 48 bytes.\n",
    "\n",
    "More on this later.\n",
    "\n",
    "\n",
    "##### Define a field_to_curve function to take field element to $\\mathbb{G}_1$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "First, we need a way to take a message and hash it to an element of the field, so we use ...\n",
    "\n",
    "#### Listing 3: \"try and increment\" algorithm for hashing onto $\\mathbb{Z}_n$\n",
    "\n",
    "<blockquote>\n",
    "Require: n ∈ Z with |n|_2 = k and s ∈ {0,1}*\n",
    "    \n",
    "$\\quad$ procedure Try-and-Increment(n, k, s)\n",
    "\n",
    "$\\qquad$    c ← 0\n",
    "\n",
    "$\\qquad$   repeat\n",
    "\n",
    "$\\qquad\\quad$       s' ← s || c_bits()\n",
    "\n",
    "$\\qquad\\quad$        z ← H(s')_0 · 2^0 + H(s')_1 · 2^1 + ... + H(s')_k · 2^k\n",
    "\n",
    " $\\qquad\\quad$       c ← c + 1\n",
    " \n",
    " $\\qquad$   until z < n\n",
    " \n",
    " $\\qquad$   return z\n",
    " \n",
    "$\\quad$ end procedure\n",
    "\n",
    "Ensure: z ∈ Z_n\n",
    "</blockquote>\n",
    "     \n",
    "possible impl [here](https://github.com/ARPA-Network/BLS-TSS-Network/blob/75da9ae432516002b12e37b16b4a4b3568c79529/crates/threshold-bls/src/hash/try_and_increment.rs)\n",
    "\n",
    "tl;dr $\\texttt{try-and-increment}:\\{0,1\\}^*\\to\\mathbb{Z}_r;m_2\\to m_{\\mathbb{Z}_r}\\simeq m_{\\mathbb{F}_r}$, which is what is given in moon math manual.\n",
    "\n",
    "This seems easy enough, but would fail security audits. We should implement a more rigorous method for a given level of security, which for us is 128-bit. An example might be `expand_message_xmd` specified again by RFC 9380, an example impl of which could be:\n",
    "\n",
    "#### Listing 4: expand_message_xmd for hash_to_field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [],
   "source": [
    "use sha2::{Sha256, Digest};\n",
    "use num_bigint::BigUint;\n",
    "use num_traits::Num;\n",
    "\n",
    "const B_IN_BYTES: usize = 32; // 256 bits for SHA-256\n",
    "const S_IN_BYTES: usize = 64; // Input block size for SHA-256\n",
    "const L: usize = 48; // ceil((254 + 128) / 8) = 48 bytes\n",
    "\n",
    "const P: &str = \"21888242871839275222246405745257275088696311157297823662689037894645226208583\";\n",
    "fn expand_message_xmd(msg: &[u8], dst: &[u8], len_in_bytes: usize) -> Vec<u8> {\n",
    "    let ell = (len_in_bytes + B_IN_BYTES - 1) / B_IN_BYTES;\n",
    "    \n",
    "    assert!(ell <= 255, \"ell is too large\");\n",
    "    assert!(len_in_bytes <= 65535, \"len_in_bytes is too large\");\n",
    "    assert!(dst.len() <= 255, \"DST is too long\");\n",
    "\n",
    "    let dst_prime: Vec<u8> = [dst, &(dst.len() as u8).to_be_bytes()].concat();\n",
    "    let z_pad = vec![0u8; S_IN_BYTES];\n",
    "    let l_i_b_str = (len_in_bytes as u16).to_be_bytes();\n",
    "\n",
    "    let msg_prime: Vec<u8> = [\n",
    "        &z_pad[..],\n",
    "        msg,\n",
    "        &l_i_b_str,\n",
    "        &[0u8],\n",
    "        &dst_prime[..]\n",
    "    ].concat();\n",
    "\n",
    "    let mut b_0 = Sha256::digest(&msg_prime);\n",
    "    let mut b_1 = Sha256::digest(&[&b_0[..], &[1u8], &dst_prime[..]].concat());\n",
    "\n",
    "    let mut uniform_bytes = b_1.to_vec();\n",
    "\n",
    "    for i in 2..=ell {\n",
    "        let b_i = Sha256::digest(\n",
    "            &[\n",
    "                &xor(&b_0, &b_1)[..],\n",
    "                &[i as u8],\n",
    "                &dst_prime[..]\n",
    "            ].concat()\n",
    "        );\n",
    "        uniform_bytes.extend_from_slice(&b_i);\n",
    "        b_1 = b_i;\n",
    "    }\n",
    "\n",
    "    uniform_bytes.truncate(len_in_bytes);\n",
    "    uniform_bytes\n",
    "}\n",
    "\n",
    "fn xor(a: &[u8], b: &[u8]) -> Vec<u8> {\n",
    "    a.iter().zip(b.iter()).map(|(&x, &y)| x ^ y).collect()\n",
    "}\n",
    "\n",
    "fn i2osp(x: usize, len: usize) -> Vec<u8> {\n",
    "    x.to_be_bytes()[std::mem::size_of::<usize>() - len..].to_vec()\n",
    "}\n",
    "\n",
    "fn hash_to_field(msg: &[u8], dst: &[u8]) -> BigUint {\n",
    "    let uniform_bytes = expand_message_xmd(msg, dst, L);\n",
    "    let mut integer = BigUint::from_bytes_be(&uniform_bytes);\n",
    "    let p = BigUint::from_str_radix(P, 10).unwrap();\n",
    "    integer %= &p;\n",
    "    integer\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "Now having the message in the field, we need to map it to $\\mathbb{G}_1$, aka a pair of $(x,y)\\in \\rm E(\\mathbb{F}_r)$\n",
    "\n",
    "\n",
    "It seems the nicest would be the Simplified Shallue-van de Woestijne method. I won't waste time on this one unfortunately, because despite there being an existing impl of [this](https://github.com/zkcrypto/bls12_381/blob/4df45188913e9d66ef36ae12825865347eed4e1b/src/hash_to_curve/map_g2.rs#L388), it requires that in its short affine Weierstrass form that $A\\neq 0$ and $B\\neq 0$, so we instead present the full ...\n",
    "\n",
    "##### Shallue-van de Woestrijne method\n",
    "\n",
    "Needed constants: \n",
    "- A=0, B=3 for bn254 \n",
    "- $Z\\in\\mathbb{F}_r$ such that\n",
    "  - for $y^2=g(x)=x^3+Ax+B$, $g(Z)\\neq 0$ in the field\n",
    "  - $-\\frac{3Z^2+4A}{4g(Z)}\\neq 0$ in the field\n",
    "      - ALSO this quantity must be a square in the field\n",
    "  - At least one of $g(Z)$ and $g(-Z/2)$ is square in the field\n",
    "\n",
    "#### Listing 5: A sage script to find such a $Z$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [],
   "source": [
    "# Arguments:\n",
    "# - F, a field object, e.g., F = GF(2^521 - 1)\n",
    "# - A and B, the coefficients of the curve y^2 = x^3 + A * x + B\n",
    "def find_z_svdw(F, A, B, init_ctr=1):\n",
    "    g = lambda x: F(x)^3 + F(A) * F(x) + F(B)\n",
    "    h = lambda Z: -(F(3) * Z^2 + F(4) * A) / (F(4) * g(Z))\n",
    "    # NOTE: if init_ctr=1 fails to find Z, try setting it to F.gen()\n",
    "    ctr = init_ctr\n",
    "    while True:\n",
    "        for Z_cand in (F(ctr), F(-ctr)):\n",
    "            # Criterion 1:\n",
    "            #   g(Z) != 0 in F.\n",
    "            if g(Z_cand) == F(0):\n",
    "                continue\n",
    "            # Criterion 2:\n",
    "            #   -(3 * Z^2 + 4 * A) / (4 * g(Z)) != 0 in F.\n",
    "            if h(Z_cand) == F(0):\n",
    "                continue\n",
    "            # Criterion 3:\n",
    "            #   -(3 * Z^2 + 4 * A) / (4 * g(Z)) is square in F.\n",
    "            if not is_square(h(Z_cand)):\n",
    "                continue\n",
    "            # Criterion 4:\n",
    "            #   At least one of g(Z) and g(-Z / 2) is square in F.\n",
    "            if is_square(g(Z_cand)) or is_square(g(-Z_cand / F(2))):\n",
    "                return Z_cand\n",
    "        ctr += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "LOL all this to show that for BN254, $Z=1\\in\\mathbb{F}_r$ ...\n",
    "\n",
    "Using the notation and utility functions from [here](https://datatracker.ietf.org/doc/html/rfc9380#name-utility-functions), I summarise the SvW algorithm for input $u\\in\\mathbb{F}_r$.\n",
    "\n",
    "Note that the constant c3 below MUST be chosen such that sgn0(c3) = 0. In other words, if the square-root computation returns a value cx such that sgn0(cx) = 1, set c3 = -cx; otherwise, set c3 = cx.\n",
    "\n",
    "Constants:\n",
    "1. $c1 = g(Z)$\n",
    "2. $c2 = -Z / 2$\n",
    "3. $c3 = \\sqrt{-g(Z) * (3Z^2 + 4A)}$     # sgn0(c3) MUST equal 0\n",
    "4. $c4 = -4g(Z) / (3Z^2 + 4A)$\n",
    "\n",
    "#### Listing 6: the SvW algorithm $A:\\mathbb{F}_r\\to \\mathbb{F}_r\\times\\mathbb{F}_r$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "tv1 = u^2\n",
    " tv1 = tv1 * c1\n",
    " tv2 = 1 + tv1\n",
    " tv1 = 1 - tv1\n",
    " tv3 = tv1 * tv2\n",
    " tv3 = inv0(tv3)\n",
    " tv4 = u * tv1\n",
    " tv4 = tv4 * tv3\n",
    " tv4 = tv4 * c3\n",
    " x1 = c2 - tv4\n",
    "gx1 = x1^2\n",
    "gx1 = gx1 + A\n",
    "gx1 = gx1 * x1\n",
    "gx1 = gx1 + B\n",
    " e1 = is_square(gx1)\n",
    " x2 = c2 + tv4\n",
    "gx2 = x2^2\n",
    "gx2 = gx2 + A\n",
    "gx2 = gx2 * x2\n",
    "gx2 = gx2 + B\n",
    " e2 = is_square(gx2) AND NOT e1   # Avoid short-circuit logic ops\n",
    " x3 = tv2^2\n",
    " x3 = x3 * tv3\n",
    " x3 = x3^2\n",
    " x3 = x3 * c4\n",
    " x3 = x3 + Z\n",
    "  x = CMOV(x3, x1, e1)   # x = x1 if gx1 is square, else x = x3\n",
    "  x = CMOV(x, x2, e2)    # x = x2 if gx2 is square and gx1 is not\n",
    " gx = x^2\n",
    " gx = gx + A\n",
    " gx = gx * x\n",
    " gx = gx + B\n",
    "  y = sqrt(gx)\n",
    " e3 = sgn0(u) == sgn0(y)\n",
    "  y = CMOV(-y, y, e3)       # Select correct sign of y\n",
    "return (x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Then poof! We have the following procedure:\n",
    "\n",
    "1. **Hashing to element of the field:** use listing 4 to convert the bits of the message to an integer of desired size and field via try-and-increment\n",
    "    a. `hash_to_field` : $\\{0,1\\}^*\\to\\mathbb{F}_r; m_2\\to m_{\\mathbb{F}_r}$\n",
    "3. **Hashing element of the field to the curve:** use listings 5-6 to then map hashed message to the curve!\n",
    "    a. `field_to_curve` : $\\mathbb{F}_r\\to\\mathbb{G}_1; m_{\\mathbb{F}_r}\\to H(m)$\n",
    "5. **Signing of the hash:** now, take the hash and sign it with the partial private key of this node\n",
    "    a. $\\sigma_i: \\mathbb{G}_1\\to\\mathbb{G}_1; H(m)\\to s_iH(m)$ with $s_i$ the partial private key $\\in\\mathbb{F}_r$ from step 2\n",
    "    \n",
    "Each participant has now signed the hashed message to the curve.\n",
    "\n",
    "### Step 5: partial verification\n",
    "\n",
    "This is pretty straightforward up to deciding how to implement the pairing function.... which is ... easy ... right? Wrong. See 'Field extentions' for the clusterfuck that is pairing maths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [],
   "source": [
    "let public_polynomial_per_share = (0..n).map(|i| {\n",
    "    public_polynomial_g2_coeffs.iter().rev().fold(Scalar::zero(), |mut sum, coeff| {\n",
    "        sum.mul(i+1);\n",
    "        sum.add(coeff);\n",
    "        Eval<Scalar> {\n",
    "            idx: i+1,\n",
    "            value: sum\n",
    "        }\n",
    "    }\n",
    "}).collect::<Vec<_>>(); //these are the values of public poly we'll use for verification\n",
    "let all_verified = (0..n).map(|i|{\n",
    "        let lhs = pairing(partials_sigs_g1[i], <generator of g_2>);\n",
    "        let rhs = pairing(<hash to be saved from previous calculation>, public_polynomial_per_share[i])\n",
    "        lhs == rhs\n",
    "    }).sum() == n - 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 6: Aggregation\n",
    "First, get lagrange coeffs $\\lambda_i$ to recombine the partial signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [],
   "source": [
    "fn lagrange_coefficient(i: usize, indices: &[usize]) -> Scalar {\n",
    "    let x_i = Scalar::from(i as u64);\n",
    "    indices.iter().filter(|&&j| j != i).fold(Scalar::one(), |acc, &j| {\n",
    "        let x_j = Scalar::from(j as u64);\n",
    "        acc * (x_j * (x_j - x_i).inverse().unwrap())\n",
    "    })\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can aggregate the signatures to create $\\sigma=\\sum_i\\lambda_i\\sigma_i$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [],
   "source": [
    "fn aggregate_signatures(partial_sigs: &[(usize, <point in G1>)]) -> <point in G1> {\n",
    "    let indices: Vec<usize> = partial_sigs.iter().map(|&(i, _)| i).collect();\n",
    "    \n",
    "    partial_sigs.iter().map(|&(i, sig)| {\n",
    "        let lambda_i = lagrange_coefficient(i, &indices);\n",
    "        sig.mul(lambda_i)\n",
    "    }).sum()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In reality we don't need all partials (handle edge cases, plus verify each partial individual first for data integrity, etc)\n",
    "\n",
    "### Step 7: Final verify\n",
    "\n",
    "Use same code as step 5 to verify the final signature $\\sigma$. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rust",
   "language": "rust",
   "name": "rust"
  },
  "language_info": {
   "codemirror_mode": "rust",
   "file_extension": ".rs",
   "mimetype": "text/rust",
   "name": "Rust",
   "pygment_lexer": "rust",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
